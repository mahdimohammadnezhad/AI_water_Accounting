{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from isimip_client.client import ISIMIPClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download isimip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≠Ô∏è Skipping pr | gfdl-esm4 | ssp126\n",
      "‚è≠Ô∏è Skipping pr | gfdl-esm4 | ssp370\n",
      "‚è≠Ô∏è Skipping pr | gfdl-esm4 | ssp585\n",
      "‚è≠Ô∏è Skipping pr | ipsl-cm6a-lr | ssp126\n",
      "‚è≠Ô∏è Skipping pr | ipsl-cm6a-lr | ssp585\n",
      "‚è≠Ô∏è Skipping pr | mpi-esm1-2-hr | ssp126\n",
      "‚è≠Ô∏è Skipping pr | mpi-esm1-2-hr | ssp370\n",
      "‚è≠Ô∏è Skipping pr | ipsl-cm6a-lr | ssp370\n",
      "‚è≠Ô∏è Skipping pr | mri-esm2-0 | ssp126\n",
      "‚è≠Ô∏è Skipping pr | mri-esm2-0 | ssp370\n",
      "‚è≠Ô∏è Skipping pr | ukesm1-0-ll | ssp126\n",
      "‚è≠Ô∏è Skipping pr | ukesm1-0-ll | ssp585\n",
      "‚è≠Ô∏è Skipping tas | gfdl-esm4 | ssp370\n",
      "‚è≠Ô∏è Skipping tas | gfdl-esm4 | ssp585\n",
      "‚è≠Ô∏è Skipping tas | ipsl-cm6a-lr | ssp126\n",
      "‚è≠Ô∏è Skipping tas | mpi-esm1-2-hr | ssp370\n",
      "‚è≠Ô∏è Skipping tas | ipsl-cm6a-lr | ssp585\n",
      "‚è≠Ô∏è Skipping tas | ipsl-cm6a-lr | ssp370\n",
      "‚è≠Ô∏è Skipping tas | mpi-esm1-2-hr | ssp126\n",
      "‚è≠Ô∏è Skipping tas | mri-esm2-0 | ssp126\n",
      "‚è≠Ô∏è Skipping tas | mpi-esm1-2-hr | ssp585\n",
      "‚è≠Ô∏è Skipping tas | mri-esm2-0 | ssp370\n",
      "‚è≠Ô∏è Skipping tas | mri-esm2-0 | ssp585\n",
      "‚è≠Ô∏è Skipping tas | ukesm1-0-ll | ssp126\n",
      "‚è≠Ô∏è Skipping tas | ukesm1-0-ll | ssp370\n",
      "‚è≠Ô∏è Skipping tas | ukesm1-0-ll | ssp585\n",
      "job 22ebb2598970b612bb147a1372c64a2a3231ad98 finished {'created_files': 9, 'total_files': 9}\n",
      "job 342a4c8051515c843dd0ab3c95736fc9b83629b3 finished {'created_files': 9, 'total_files': 9}\n",
      "job 704beca5c3b9556a4fc51513d5dece33b8498c0d finished {'created_files': 9, 'total_files': 9}\n",
      "job 385dc21108526426566b20a877f454b96e0501f1 finished {'created_files': 9, 'total_files': 9}\n",
      "‚úÖ Downloaded pr | mri-esm2-0 | ssp585\n",
      "‚úÖ Downloaded pr | mpi-esm1-2-hr | ssp585\n",
      "‚úÖ Downloaded pr | ukesm1-0-ll | ssp370\n",
      "‚úÖ Downloaded tas | gfdl-esm4 | ssp126\n",
      "\n",
      "üéØ All downloads complete.\n"
     ]
    }
   ],
   "source": [
    "# ------------------ ÿ™ŸÜÿ∏€åŸÖÿßÿ™ ------------------\n",
    "\n",
    "variables = [\"pr\", \"tas\"]\n",
    "\n",
    "scenarios = [\"ssp126\", \"ssp370\", \"ssp585\"]\n",
    "\n",
    "models = [\n",
    "    \"gfdl-esm4\",\n",
    "    \"ipsl-cm6a-lr\",\n",
    "    \"mpi-esm1-2-hr\",\n",
    "    \"mri-esm2-0\",\n",
    "    \"ukesm1-0-ll\"\n",
    "]\n",
    "\n",
    "WATERSHED_SHP_PATH = r\"E:\\Term2\\WERI\\thesis_AB\\Research\\code\\shp\\Mashhad.shp\"\n",
    "base_download_dir = \"isimip\"\n",
    "\n",
    "os.makedirs(base_download_dir, exist_ok=True)\n",
    "\n",
    "client = ISIMIPClient()\n",
    "\n",
    "# ------------------ ÿÆŸàÿßŸÜÿØŸÜ shapefile ------------------\n",
    "\n",
    "gdf = gpd.read_file(WATERSHED_SHP_PATH)\n",
    "lonmin, latmin, lonmax, latmax = gdf.total_bounds\n",
    "\n",
    "# ------------------ ÿ™Ÿàÿßÿ®ÿπ ------------------\n",
    "\n",
    "def get_filtered_files(var, model, sce):\n",
    "    response = client.datasets(\n",
    "        simulation_round=\"ISIMIP3b\",\n",
    "        product=\"InputData\",\n",
    "        climate_forcing=model,\n",
    "        climate_scenario=sce,\n",
    "        climate_variable=var\n",
    "    )\n",
    "\n",
    "    file_paths = []\n",
    "    for dataset in response[\"results\"]:\n",
    "        for f in dataset[\"files\"]:\n",
    "            file_paths.append(f[\"path\"])\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def download_for_site(var, model, sce):\n",
    "    var_dir = os.path.join(base_download_dir, var, model, sce)\n",
    "    os.makedirs(var_dir, exist_ok=True)\n",
    "\n",
    "    if os.listdir(var_dir):\n",
    "        print(f\"‚è≠Ô∏è Skipping {var} | {model} | {sce}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        files = get_filtered_files(var, model, sce)\n",
    "\n",
    "        cutout = client.cutout(\n",
    "            files,\n",
    "            [latmin, latmax, lonmin, lonmax],\n",
    "            poll=10\n",
    "        )\n",
    "\n",
    "        client.download(\n",
    "            cutout[\"file_url\"],\n",
    "            path=var_dir,\n",
    "            validate=False,\n",
    "            extract=False\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ Downloaded {var} | {model} | {sce}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error {var} | {model} | {sce}: {e}\")\n",
    "\n",
    "# ------------------ ÿßÿ¨ÿ±ÿß€å ŸÖŸàÿßÿ≤€å ------------------\n",
    "\n",
    "max_workers = 8\n",
    "futures = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    for var in variables:\n",
    "        for model in models:\n",
    "            for sce in scenarios:\n",
    "                futures.append(\n",
    "                    executor.submit(download_for_site, var, model, sce)\n",
    "                )\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        future.result()\n",
    "\n",
    "print(\"\\nüéØ All downloads complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(points))\n",
    "for index, point in enumerate(points):\n",
    "    lat, lon, download_path = point\n",
    "    frames = []\n",
    "    for file in sorted(Path(download_path).iterdir()):\n",
    "        if file.suffix == '.csv':\n",
    "            frames.append(pd.read_csv(file, names=['date', 'pr'], index_col='date', parse_dates=True))\n",
    "    \n",
    "    df = pd.concat(frames)\n",
    "    df.plot(ax=axes[index], title=download_path, xlim=('2020-01-01', '2030-01-01'))\n",
    "\n",
    "plt.gcf().set_size_inches(20, 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
